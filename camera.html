<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Chair Squat</title>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.12.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

<style>
html, body {
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  overflow: hidden;
  background: black;
}
video, canvas {
  position: fixed;
  top: 0;
  left: 0;
  width: 100vw;
  height: 100vh;
  object-fit: cover;
}
#ui {
  position: fixed;
  top: 10px;
  width: 100%;
  text-align: center;
  z-index: 3;
  color: white;
  font-family: Arial;
}
#count {
  font-size: 60px;
  font-weight: bold;
}
button {
  font-size: 22px;
  padding: 10px 25px;
  border-radius: 8px;
  border: none;
  background: red;
  color: white;
}
</style>
</head>

<body>

<video id="video" autoplay playsinline muted></video>
<canvas id="canvas"></canvas>

<div id="ui">
  <div id="count">0</div>
  <button onclick="stopExercise()">STOP</button>
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");

let detector;
let count = 0;
let stage = "up";
let active = true;
let target = 5;

let lastDetectTime = 0;

// ðŸ”´ ANDROID CAMERA FIX
async function startCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: {
      facingMode: "environment", // BACK CAMERA
      width: { ideal: 640 },
      height: { ideal: 480 },
      frameRate: { ideal: 30, max: 30 }
    }
  });

  video.srcObject = stream;
  await video.play();

  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;

  detector = await poseDetection.createDetector(
    poseDetection.SupportedModels.MoveNet,
    { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING }
  );

  requestAnimationFrame(loop);
}

// ANGLE
function angle(a, b, c) {
  const ab = { x: b.x - a.x, y: b.y - a.y };
  const cb = { x: b.x - c.x, y: b.y - c.y };
  const dot = ab.x * cb.x + ab.y * cb.y;
  const magAB = Math.hypot(ab.x, ab.y);
  const magCB = Math.hypot(cb.x, cb.y);
  if (!magAB || !magCB) return 0;
  return Math.acos(Math.min(Math.max(dot / (magAB * magCB), -1), 1)) * 180 / Math.PI;
}

// ðŸ” LOOP WITH THROTTLE
async function loop(timestamp) {
  if (!active) return;

  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  if (timestamp - lastDetectTime > 100) { // ðŸ‘ˆ 10 FPS detection
    lastDetectTime = timestamp;

    const poses = await detector.estimatePoses(video);
    if (poses.length) {
      const kp = poses[0].keypoints;

      // ðŸ”´ RIGHT LEG (ANDROID STABLE)
      const hip = kp[12];
      const knee = kp[14];
      const ankle = kp[16];

      if (hip.score > 0.25 && knee.score > 0.25 && ankle.score > 0.25) {
        const a = angle(hip, knee, ankle);

        if (a < 150 && stage === "up") stage = "down";
        if (a > 165 && stage === "down") {
          stage = "up";
          count++;
          document.getElementById("count").innerText = count;

          if (count >= target) finish();
        }
      }
    }
  }

  requestAnimationFrame(loop);
}

function finish() {
  active = false;
  stopCamera();
  document.getElementById("count").innerText = "âœ” DONE";
  setTimeout(() => location.href = "exercise.html", 1500);
}

function stopCamera() {
  if (video.srcObject)
    video.srcObject.getTracks().forEach(t => t.stop());
}

function stopExercise() {
  active = false;
  stopCamera();
  location.href = "exercise.html";
}

startCamera();
</script>

</body>
</html>
